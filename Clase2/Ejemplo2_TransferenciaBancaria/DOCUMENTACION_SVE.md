# ğŸ“Š DOCUMENTACIÃ“N: Reportes SVE (Standard Verification Environment)

## Â¿QuÃ© es SVE?

**SVE (Standard Verification Environment)** es un formato estÃ¡ndar utilizado en la industria bancaria y financiera para documentar resultados de pruebas de software. Este formato permite:

- âœ… Trazabilidad completa de casos de prueba
- âœ… IntegraciÃ³n con sistemas de gestiÃ³n de calidad
- âœ… AuditorÃ­a y cumplimiento normativo
- âœ… Reportes ejecutivos y tÃ©cnicos
- âœ… AnÃ¡lisis de tendencias de calidad

---

## ğŸ¯ CaracterÃ­sticas de los Reportes SVE Generados

### Formatos Disponibles

1. **XML** (`sve_report.xml`)
   - Formato estÃ¡ndar de intercambio
   - Compatible con herramientas de QA empresariales
   - Estructura jerÃ¡rquica clara
   - Validable con esquemas XSD

2. **JSON** (`sve_report.json`)
   - Ideal para APIs y automatizaciÃ³n
   - FÃ¡cil integraciÃ³n con dashboards
   - Compatible con herramientas modernas de anÃ¡lisis

3. **CSV** (`sve_report.csv`)
   - Abre directamente en Excel
   - AnÃ¡lisis rÃ¡pido con tablas dinÃ¡micas
   - FÃ¡cil de compartir con stakeholders

---

## ğŸ“‹ Estructura del Reporte SVE

### 1. Metadata (Metadatos)
InformaciÃ³n general del proyecto y ejecuciÃ³n:

```json
{
  "metadata": {
    "project": "API Transferencias Bancarias - Testing QA",
    "generated_at": "2025-12-10T12:32:07.206286",
    "test_framework": "pytest",
    "environment": "Development"
  }
}
```

### 2. Summary (Resumen Ejecutivo)
MÃ©tricas agregadas de la ejecuciÃ³n:

```json
{
  "summary": {
    "total_tests": 15,
    "passed": 13,
    "failed": 0,
    "skipped": 2,
    "errors": 0,
    "pass_rate": "86.67%",
    "total_duration": "77.49s"
  }
}
```

### 3. Test Cases (Casos de Prueba Detallados)
InformaciÃ³n completa de cada test:

```json
{
  "test_id": "TC-01",
  "test_name": "test_01_transferencia_exitosa",
  "status": "PASS",
  "duration": 4.093,
  "scenario": "Transferencia exitosa con datos vÃ¡lidos",
  "expected_result": "HTTP 200, estado COMPLETED",
  "actual_result": "Test ejecutado exitosamente segÃºn lo esperado",
  "error_message": "",
  "preconditions": "Cuentas vÃ¡lidas, saldo suficiente",
  "test_data": {...},
  "timestamp": "2025-12-10T12:30:53.620260"
}
```

---

## ğŸš€ CÃ³mo Generar Reportes SVE

### MÃ©todo 1: Usar el Script PowerShell (Recomendado)

```powershell
.\run_tests_sve.ps1
```

Este script:
1. âœ… Configura el entorno automÃ¡ticamente
2. âœ… Limpia reportes anteriores
3. âœ… Ejecuta todos los tests
4. âœ… Genera los 3 formatos SVE (XML, JSON, CSV)
5. âœ… Muestra resumen de resultados

### MÃ©todo 2: Ejecutar pytest Directamente

```powershell
$env:AUTH_TOKEN="Bearer test"
pytest -v
```

Los reportes SVE se generan automÃ¡ticamente gracias al hook configurado en `conftest.py`.

---

## ğŸ“– CÃ³mo Leer los Reportes

### Formato XML

```xml
<TestCase id="TC-01" status="PASS">
  <Name>test_01_transferencia_exitosa_path_feliz</Name>
  <Scenario>Transferencia exitosa con datos vÃ¡lidos</Scenario>
  <Preconditions>Cuentas vÃ¡lidas, saldo suficiente, token vÃ¡lido</Preconditions>
  <ExpectedResult>HTTP 200, estado COMPLETED, saldo actualizado</ExpectedResult>
  <ActualResult>Test ejecutado exitosamente segÃºn lo esperado</ActualResult>
  <Duration>4.093s</Duration>
  <Timestamp>2025-12-10T12:30:53.620260</Timestamp>
</TestCase>
```

**Abrir con:**
```powershell
notepad sve_report.xml
# o
code sve_report.xml  # Visual Studio Code
```

### Formato JSON

```json
{
  "test_id": "TC-01",
  "test_name": "test_01_transferencia_exitosa_path_feliz",
  "status": "PASS",
  "duration": 4.093,
  "scenario": "Transferencia exitosa con datos vÃ¡lidos",
  "expected_result": "HTTP 200, estado COMPLETED, saldo actualizado",
  "actual_result": "Test ejecutado exitosamente segÃºn lo esperado"
}
```

**Abrir con:**
```powershell
code sve_report.json
# o para parsear en PowerShell:
Get-Content sve_report.json | ConvertFrom-Json
```

### Formato CSV

```csv
Test ID,Test Name,Status,Duration (s),Scenario,Expected Result,Actual Result
TC-01,test_01_transferencia_exitosa,PASS,4.093,Transferencia exitosa,...
```

**Abrir con:**
```powershell
start sve_report.csv  # Abre en Excel
```

---

## ğŸ” Casos de Uso PrÃ¡cticos

### 1. AnÃ¡lisis RÃ¡pido en Excel
```powershell
start sve_report.csv
```
Luego en Excel:
- Crear tabla dinÃ¡mica
- Filtrar por Status (PASS/FAIL/SKIP)
- Calcular promedios de duraciÃ³n
- Generar grÃ¡ficos de distribuciÃ³n

### 2. IntegraciÃ³n con CI/CD
```powershell
# En pipeline de Azure DevOps o Jenkins
pytest -v
# Publicar sve_report.xml como artefacto
# Parsear sve_report.json para mÃ©tricas
```

### 3. Dashboard de Calidad
```javascript
// Consumir JSON desde aplicaciÃ³n web
fetch('sve_report.json')
  .then(r => r.json())
  .then(data => {
    console.log(`Pass Rate: ${data.summary.pass_rate}`);
    console.log(`Total Tests: ${data.summary.total_tests}`);
  });
```

### 4. AuditorÃ­a y Trazabilidad
```powershell
# Buscar test especÃ­fico en XML
Select-String -Path "sve_report.xml" -Pattern "TC-08"

# Ver solo tests fallidos en JSON
$report = Get-Content sve_report.json | ConvertFrom-Json
$report.test_cases | Where-Object { $_.status -eq "FAIL" }
```

---

## ğŸ“Š Estados de Test Cases

| Estado | DescripciÃ³n | Color Sugerido |
|--------|-------------|----------------|
| **PASS** | Test ejecutado exitosamente | ğŸŸ¢ Verde |
| **FAIL** | Test fallÃ³ (error en funcionalidad) | ğŸ”´ Rojo |
| **SKIP** | Test omitido (condiciones no cumplidas) | ğŸŸ¡ Amarillo |
| **ERROR** | Error de infraestructura/setup | ğŸŸ  Naranja |

---

## ğŸ”§ PersonalizaciÃ³n de Metadatos

Los metadatos de cada test se definen en `tests/conftest.py`:

```python
TEST_METADATA = {
    "test_01_transferencia_exitosa": {
        "id": "TC-01",
        "scenario": "Transferencia exitosa con datos vÃ¡lidos",
        "expected": "HTTP 200, estado COMPLETED",
        "preconditions": "Cuentas vÃ¡lidas, saldo suficiente"
    },
    # ... mÃ¡s tests
}
```

Para agregar un nuevo test al reporte SVE:
1. Agregar entrada en `TEST_METADATA`
2. Definir `id`, `scenario`, `expected`, `preconditions`
3. Ejecutar tests normalmente

---

## ğŸ“ˆ MÃ©tricas Incluidas en el Reporte

### MÃ©tricas de EjecuciÃ³n
- âœ… **Total Tests**: Cantidad total de casos de prueba
- âœ… **Passed**: Tests exitosos
- âœ… **Failed**: Tests fallidos
- âœ… **Skipped**: Tests omitidos
- âœ… **Errors**: Errores de infraestructura
- âœ… **Pass Rate**: Porcentaje de Ã©xito (Passed / Total)
- âœ… **Total Duration**: Tiempo total de ejecuciÃ³n

### MÃ©tricas por Test Case
- âœ… **Duration**: Tiempo de ejecuciÃ³n individual
- âœ… **Timestamp**: Momento exacto de ejecuciÃ³n
- âœ… **Status**: Estado final del test
- âœ… **Error Message**: Detalles de errores (si aplica)
- âœ… **Test Data**: Datos utilizados en el test

---

## ğŸ¯ Ejemplo de AnÃ¡lisis de Resultados

### AnÃ¡lisis de DuraciÃ³n de Tests

```powershell
# PowerShell: Encontrar tests mÃ¡s lentos
$report = Get-Content sve_report.json | ConvertFrom-Json
$report.test_cases | 
    Sort-Object -Property duration -Descending | 
    Select-Object -First 5 test_name, duration
```

### Tasa de Ã‰xito por CategorÃ­a

```powershell
# Ver distribuciÃ³n de estados
$report = Get-Content sve_report.json | ConvertFrom-Json
$report.test_cases | 
    Group-Object status | 
    Select-Object Name, Count
```

---

## ğŸ”— IntegraciÃ³n con Herramientas Empresariales

### Jenkins
```groovy
// Publicar resultados SVE
publishHTML([
    reportDir: '.',
    reportFiles: 'sve_report.xml',
    reportName: 'SVE Test Report'
])
```

### Azure DevOps
```yaml
# azure-pipelines.yml
- task: PublishTestResults@2
  inputs:
    testResultsFormat: 'JUnit'
    testResultsFiles: 'sve_report.xml'
```

### Jira / TestRail
- Importar `sve_report.csv` directamente
- Mapear columnas: Test ID â†’ Case ID
- Actualizar resultados automÃ¡ticamente

---

## ğŸ“ Archivos del Sistema SVE

```
Ejemplo2_TransferenciaBancaria/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ sve_reporter.py         # Motor de generaciÃ³n SVE
â”‚   â”œâ”€â”€ conftest.py             # ConfiguraciÃ³n pytest + SVE
â”‚   â””â”€â”€ test_transferencias.py  # Tests con metadatos
â”œâ”€â”€ run_tests_sve.ps1           # Script automatizado
â”œâ”€â”€ sve_report.xml              # Reporte XML âœ…
â”œâ”€â”€ sve_report.json             # Reporte JSON âœ…
â””â”€â”€ sve_report.csv              # Reporte CSV âœ…
```

---

## ğŸ“ Beneficios del Formato SVE

### Para QA
- âœ… Trazabilidad completa de cada test
- âœ… Evidencia para auditorÃ­as
- âœ… FÃ¡cil identificaciÃ³n de regresiones

### Para Developers
- âœ… Detalles tÃ©cnicos de fallos
- âœ… DuraciÃ³n de tests para optimizaciÃ³n
- âœ… IntegraciÃ³n con CI/CD

### Para Managers
- âœ… Pass Rate visible al instante
- âœ… Reportes ejecutivos en Excel
- âœ… MÃ©tricas de calidad objetivas

### Para AuditorÃ­a
- âœ… Formato estÃ¡ndar reconocido
- âœ… Timestamps de ejecuciÃ³n
- âœ… Datos de prueba documentados

---

## ğŸš¨ Troubleshooting

### Problema: No se generan reportes SVE
**SoluciÃ³n:**
```powershell
# Verificar que conftest.py estÃ© en tests/
ls tests/conftest.py

# Verificar imports de pytest
python -c "import pytest; print(pytest.__version__)"
```

### Problema: Reportes vacÃ­os
**SoluciÃ³n:**
```powershell
# Ejecutar con verbose para ver hooks
pytest -v --debug
```

### Problema: Encoding incorrecto en CSV
**SoluciÃ³n:**
```powershell
# Abrir CSV con encoding UTF-8
Get-Content sve_report.csv -Encoding UTF8
```

---

## ğŸ“š Referencias y EstÃ¡ndares

- **IEEE 829**: Standard for Software Test Documentation
- **ISO/IEC 29119**: Software Testing Standards
- **SVE Framework**: Banking Industry Best Practices

---

## ğŸ‰ Resumen

Los reportes SVE proveen:
1. âœ… **3 formatos** (XML, JSON, CSV)
2. âœ… **GeneraciÃ³n automÃ¡tica** con cada ejecuciÃ³n de pytest
3. âœ… **Metadatos completos** de cada test case
4. âœ… **MÃ©tricas ejecutivas** (pass rate, duraciÃ³n, etc.)
5. âœ… **Trazabilidad** completa para auditorÃ­as
6. âœ… **IntegraciÃ³n fÃ¡cil** con herramientas empresariales

---

**Para generar reportes ahora:**
```powershell
.\run_tests_sve.ps1
```

**Archivos generados:**
- `sve_report.xml` - Formato XML estÃ¡ndar
- `sve_report.json` - Formato JSON para APIs
- `sve_report.csv` - Formato CSV para Excel

---

**DocumentaciÃ³n completa**: Este archivo  
**CÃ³digo fuente**: `tests/sve_reporter.py`  
**ConfiguraciÃ³n**: `tests/conftest.py`  
**Script automatizado**: `run_tests_sve.ps1`
