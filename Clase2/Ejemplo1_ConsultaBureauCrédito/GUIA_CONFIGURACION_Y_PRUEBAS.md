# üß™ Gu√≠a Completa de Configuraci√≥n y Ejecuci√≥n de Tests - Bureau de Cr√©dito

## üìã Tabla de Contenidos
1. [Requisitos Previos](#requisitos-previos)
2. [Instalaci√≥n Paso a Paso](#instalaci√≥n-paso-a-paso)
3. [Configuraci√≥n del Entorno](#configuraci√≥n-del-entorno)
4. [Verificaci√≥n de la Instalaci√≥n](#verificaci√≥n-de-la-instalaci√≥n)
5. [Ejecuci√≥n de Tests](#ejecuci√≥n-de-tests)
6. [Interpretaci√≥n de Resultados](#interpretaci√≥n-de-resultados)
7. [Troubleshooting](#troubleshooting)
8. [Ejemplos Pr√°cticos](#ejemplos-pr√°cticos)

---

## üìå Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado:

### Software Requerido
- ‚úÖ **Python 3.8 o superior**
- ‚úÖ **pip** (gestor de paquetes de Python)
- ‚úÖ **PowerShell** (Windows)
- ‚úÖ **Git** (opcional, para control de versiones)

### API del Bureau de Cr√©dito
- ‚úÖ API corriendo en `localhost:8000`
- ‚úÖ Acceso a la documentaci√≥n en `http://localhost:8000/docs`

### Verificar Instalaciones

```powershell
# Verificar Python
python --version
# Debe mostrar: Python 3.8.x o superior

# Verificar pip
pip --version
# Debe mostrar: pip 20.x.x o superior

# Verificar conectividad del API
Test-NetConnection -ComputerName localhost -Port 8000
```

---

## üöÄ Instalaci√≥n Paso a Paso

### Paso 1: Navegar al Directorio del Proyecto

```powershell
cd C:\Users\1577089\Desktop\CapacitacionIA-Banistmo\CapacitacionIA-Banistmo
```

### Paso 2: Crear Entorno Virtual (Recomendado)

Un entorno virtual mantiene las dependencias aisladas del sistema.

```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
.\venv\Scripts\activate

# Ver√°s (venv) al inicio de tu l√≠nea de comando
# (venv) PS C:\Users\1577089\Desktop\...>
```

**Nota:** Para desactivar el entorno virtual m√°s tarde, usa:
```powershell
deactivate
```

### Paso 3: Instalar Dependencias

```powershell
# Con el entorno virtual activado, instalar todas las dependencias
pip install -r requirements.txt

# Esto instalar√°:
# - pytest 7.4.3
# - pytest-asyncio 0.21.1
# - pytest-timeout 2.2.0
# - pytest-mock 3.12.0
# - requests 2.31.0
# - httpx 0.25.2
# - faker 20.1.0
# - pydantic 2.5.2
# - python-dotenv 1.0.0
```

### Paso 4: Verificar Instalaci√≥n de pytest

```powershell
pytest --version

# Salida esperada:
# pytest 7.4.3
```

---

## ‚öôÔ∏è Configuraci√≥n del Entorno

### Paso 1: Configurar Variables de Entorno

El archivo `.env` ya est√° creado con valores por defecto. Si necesitas modificarlo:

```powershell
# Ver contenido del archivo .env
cat .env
```

**Contenido del archivo `.env`:**
```ini
# Configuraci√≥n del API
API_BASE_URL=http://localhost:8000
API_TIMEOUT=5

# Configuraci√≥n de pruebas
TEST_ENVIRONMENT=dev
ENABLE_MOCK=false
```

### Paso 2: Ajustar Configuraci√≥n (Opcional)

Si tu API est√° en una URL diferente o necesitas cambiar el timeout:

```powershell
# Editar archivo .env con notepad
notepad .env

# O con VS Code
code .env
```

**Configuraciones comunes:**

| Variable | Descripci√≥n | Valores Posibles |
|----------|-------------|------------------|
| `API_BASE_URL` | URL del API Bureau | `http://localhost:8000` (local)<br>`https://api-dev.banco.com` (dev)<br>`https://api.banco.com` (prod) |
| `API_TIMEOUT` | Timeout en segundos | `5` (default)<br>`10` (para conexiones lentas) |
| `TEST_ENVIRONMENT` | Ambiente de pruebas | `dev`, `qa`, `uat`, `prod` |
| `ENABLE_MOCK` | Usar datos mock | `true`, `false` |

---

## ‚úÖ Verificaci√≥n de la Instalaci√≥n

### Checklist de Verificaci√≥n

Ejecuta estos comandos para confirmar que todo est√° configurado correctamente:

#### 1. Verificar Python y pip
```powershell
python --version  # Debe mostrar 3.8+
pip --version     # Debe estar instalado
```

#### 2. Verificar entorno virtual activo
```powershell
# Debes ver (venv) en tu prompt
# (venv) PS C:\Users\...>
```

#### 3. Verificar pytest instalado
```powershell
pytest --version

# Salida esperada:
# pytest 7.4.3
```

#### 4. Listar tests disponibles
```powershell
pytest --collect-only

# Salida esperada: Lista de 21 tests
```

#### 5. Verificar estructura de archivos
```powershell
# Listar archivos de tests
ls tests\*.py

# Debes ver:
# test_bureau_happy_path.py
# test_bureau_validations.py
# test_bureau_errors.py
# test_bureau_edge_cases.py
# conftest.py
```

#### 6. Verificar API disponible
```powershell
# Opci√≥n 1: PowerShell
Test-NetConnection -ComputerName localhost -Port 8000

# Opci√≥n 2: Navegador
# Abrir: http://localhost:8000/docs
```

### Script de Verificaci√≥n Completo

```powershell
# Ejecutar todas las verificaciones en secuencia
Write-Host "=== VERIFICACI√ìN DE INSTALACI√ìN ===" -ForegroundColor Cyan

Write-Host "`n1. Verificando Python..." -ForegroundColor Yellow
python --version

Write-Host "`n2. Verificando pytest..." -ForegroundColor Yellow
pytest --version

Write-Host "`n3. Verificando archivo .env..." -ForegroundColor Yellow
if (Test-Path .env) { Write-Host "‚úì Archivo .env encontrado" -ForegroundColor Green } else { Write-Host "‚úó Archivo .env no encontrado" -ForegroundColor Red }

Write-Host "`n4. Verificando estructura de tests..." -ForegroundColor Yellow
$testFiles = @("tests\test_bureau_happy_path.py", "tests\test_bureau_validations.py", "tests\test_bureau_errors.py", "tests\test_bureau_edge_cases.py")
foreach ($file in $testFiles) {
    if (Test-Path $file) { Write-Host "‚úì $file" -ForegroundColor Green } else { Write-Host "‚úó $file" -ForegroundColor Red }
}

Write-Host "`n5. Contando tests disponibles..." -ForegroundColor Yellow
pytest --collect-only -q

Write-Host "`n6. Verificando conectividad del API..." -ForegroundColor Yellow
Test-NetConnection -ComputerName localhost -Port 8000

Write-Host "`n=== VERIFICACI√ìN COMPLETADA ===" -ForegroundColor Cyan
```

---

## üéØ Ejecuci√≥n de Tests

### Comandos B√°sicos

#### Ejecutar TODOS los tests
```powershell
pytest

# Salida esperada: 21 tests ejecutados
# ========================= 21 passed in 5.23s =========================
```

#### Ejecutar con salida detallada (verbose)
```powershell
pytest -v

# Muestra cada test con su nombre completo y resultado
```

#### Ejecutar con salida muy detallada
```powershell
pytest -vv

# Incluye informaci√≥n adicional de debugging
```

### Ejecuci√≥n por Prioridad

#### Solo tests CR√çTICOS (P0) - 5 tests
```powershell
pytest -m critical

# Ejecuta solo los casos bloqueantes:
# - TC-BC-001: Cliente con buen historial
# - TC-BC-002: Cliente con deudas activas
# - TC-BC-003: Cliente moroso
# - TC-BC-004: Cliente en CIFIN
# - TC-BC-008: Timeout
```

#### Tests Cr√≠ticos + Alta Prioridad (P0 + P1) - 15 tests
```powershell
pytest -m "critical or high"

# Ejecuta todos los casos importantes para releases
```

#### Todos los tests por prioridad
```powershell
pytest -m "critical or high or medium"

# Ejecuta los 21 tests completos
```

### Ejecuci√≥n por Tipo de Test

#### Suite de Regresi√≥n
```powershell
pytest -m regression

# Ejecuta 13 tests de regresi√≥n
```

#### Tests de Validaci√≥n
```powershell
pytest -m validation

# Ejecuta 9 tests de validaci√≥n de entrada
```

#### Tests de Integraci√≥n
```powershell
pytest -m integration

# Ejecuta 10 tests de integraci√≥n con el API
```

#### Edge Cases
```powershell
pytest -m edge_case

# Ejecuta 6 tests de casos extremos
```

#### Smoke Tests
```powershell
pytest -m smoke

# Ejecuta 4 tests b√°sicos de humo
```

### Ejecuci√≥n por Archivo

#### Path Feliz y Casos Positivos
```powershell
pytest tests/test_bureau_happy_path.py

# Ejecuta 4 tests (TC-BC-001 a TC-BC-004)
```

#### Validaciones de Entrada
```powershell
pytest tests/test_bureau_validations.py

# Ejecuta 6 tests (TC-BC-005 a TC-BC-007 + extras)
```

#### Manejo de Errores
```powershell
pytest tests/test_bureau_errors.py

# Ejecuta 5 tests (TC-BC-008, TC-BC-009, TC-BC-015 + extras)
```

#### Edge Cases y Casos Especiales
```powershell
pytest tests/test_bureau_edge_cases.py

# Ejecuta 6 tests (TC-BC-010 a TC-BC-014 + extras)
```

### Ejecuci√≥n de Tests Espec√≠ficos

#### Por clase de test
```powershell
pytest tests/test_bureau_happy_path.py::TestBureauHappyPath

# Ejecuta todos los tests de la clase TestBureauHappyPath
```

#### Por test individual
```powershell
pytest tests/test_bureau_happy_path.py::TestBureauHappyPath::test_tc_bc_001_cliente_buen_historial

# Ejecuta solo el test TC-BC-001
```

#### M√∫ltiples tests espec√≠ficos
```powershell
pytest tests/test_bureau_happy_path.py::TestBureauHappyPath::test_tc_bc_001_cliente_buen_historial tests/test_bureau_happy_path.py::TestBureauHappyPath::test_tc_bc_004_cliente_en_lista_cifin

# Ejecuta TC-BC-001 y TC-BC-004
```

### Opciones √ötiles de Ejecuci√≥n

#### Detener en el primer error
```powershell
pytest -x

# Se detiene apenas encuentra un test fallido
```

#### Mostrar prints y logs
```powershell
pytest -s

# Muestra todos los print() y logs durante la ejecuci√≥n
```

#### Modo quiet (silencioso)
```powershell
pytest -q

# Muestra solo resumen final
```

#### Ejecutar √∫ltimos tests fallidos
```powershell
pytest --lf

# Solo ejecuta los tests que fallaron en la √∫ltima ejecuci√≥n
```

#### Ejecutar primero los fallidos, luego todos
```powershell
pytest --ff

# Ejecuta primero los fallidos, despu√©s el resto
```

### Generaci√≥n de Reportes

#### Reporte HTML
```powershell
# Instalar plugin (si no est√° instalado)
pip install pytest-html

# Generar reporte
pytest --html=report.html --self-contained-html

# Abrir reporte
start report.html
```

#### Reporte JUnit XML (para CI/CD)
```powershell
pytest --junitxml=report.xml

# Archivo XML compatible con Jenkins, GitLab CI, etc.
```

#### Reporte con Cobertura
```powershell
# Instalar plugin de cobertura
pip install pytest-cov

# Generar reporte de cobertura
pytest --cov=tests --cov-report=html

# Abrir reporte
start htmlcov/index.html
```

### Usando el Script Python

```powershell
# Todas las pruebas
python run_tests.py all

# Solo cr√≠ticas (P0)
python run_tests.py critical

# Cr√≠ticas + Alta (P0 + P1)
python run_tests.py high

# Smoke tests
python run_tests.py smoke

# Suite de regresi√≥n
python run_tests.py regression
```

---

## üìä Interpretaci√≥n de Resultados

### S√≠mbolos y Estados

| S√≠mbolo | Estado | Significado |
|---------|--------|-------------|
| `.` | PASSED | Test pas√≥ exitosamente ‚úÖ |
| `F` | FAILED | Test fall√≥ ‚ùå |
| `s` | SKIPPED | Test fue omitido ‚è≠Ô∏è |
| `x` | XFAIL | Fallo esperado (xfail) ‚ö†Ô∏è |
| `X` | XPASS | Pas√≥ cuando se esperaba fallo üéâ |
| `E` | ERROR | Error durante ejecuci√≥n üí• |

### Ejemplo de Salida Exitosa

```
tests/test_bureau_happy_path.py ....                                    [ 19%]
tests/test_bureau_validations.py ......                                 [ 47%]
tests/test_bureau_errors.py .....                                       [ 71%]
tests/test_bureau_edge_cases.py ......                                  [100%]

========================= 21 passed in 5.23s ==========================
```

**Interpretaci√≥n:**
- ‚úÖ Todos los tests pasaron (21/21)
- ‚è±Ô∏è Tiempo total: 5.23 segundos
- üìä Distribuci√≥n por archivo visible

### Ejemplo de Salida con Fallos

```
tests/test_bureau_happy_path.py .F..                                    [ 19%]

=================================== FAILURES ===================================
____________ TestBureauHappyPath.test_tc_bc_002_cliente_deudas_activas_al_dia ___________

self = <tests.test_bureau_happy_path.TestBureauHappyPath object at 0x...>
api_client = <tests.helpers.api_client.BureauAPIClient object at 0x...>

    def test_tc_bc_002_cliente_deudas_activas_al_dia(self, api_client, verificar_api_disponible):
        response = api_client.consultar_bureau(
            documento=CLIENTE_DEUDAS_ACTIVAS["documento"],
            tipo_documento=CLIENTE_DEUDAS_ACTIVAS["tipo_documento"]
        )
        
>       assert response.status_code == 200
E       AssertionError: assert 500 == 200
E        +  where 500 = <Response [500]>.status_code

tests/test_bureau_happy_path.py:85: AssertionError
======================= short test summary info ========================
FAILED tests/test_bureau_happy_path.py::TestBureauHappyPath::test_tc_bc_002_cliente_deudas_activas_al_dia
==================== 1 failed, 20 passed in 5.45s =====================
```

**Interpretaci√≥n:**
- ‚ùå 1 test fall√≥: `test_tc_bc_002_cliente_deudas_activas_al_dia`
- ‚úÖ 20 tests pasaron
- üîç Error: El API retorn√≥ status 500 en lugar de 200
- üìç L√≠nea del error: `tests/test_bureau_happy_path.py:85`

### Ejemplo de Tests Omitidos (Skipped)

```
tests/test_bureau_happy_path.py ssss                                    [ 19%]

========================= 4 skipped in 0.52s ===========================
```

**Razones comunes para skip:**
- üîå API no est√° disponible
- ‚öôÔ∏è Configuraci√≥n incorrecta
- üè∑Ô∏è Test marcado para skip con `@pytest.mark.skip`

### Resumen de Estad√≠sticas

Al final de cada ejecuci√≥n ver√°s un resumen:

```
========================= test session starts ==========================
platform win32 -- Python 3.11.0, pytest-7.4.3, pluggy-1.3.0
rootdir: C:\Users\1577089\Desktop\CapacitacionIA-Banistmo\CapacitacionIA-Banistmo
configfile: pytest.ini
testpaths: tests
plugins: asyncio-0.21.1, timeout-2.2.0, mock-3.12.0
collected 21 items

tests/test_bureau_happy_path.py ....                                    [ 19%]
tests/test_bureau_validations.py ......                                 [ 47%]
tests/test_bureau_errors.py .....                                       [ 71%]
tests/test_bureau_edge_cases.py ......                                  [100%]

========================= 21 passed in 5.23s ===========================
```

---

## üîß Troubleshooting

### Problema 1: pytest no se reconoce

**Error:**
```
pytest : El t√©rmino 'pytest' no se reconoce como nombre de un cmdlet...
```

**Soluci√≥n:**
```powershell
# 1. Activar entorno virtual
.\venv\Scripts\activate

# 2. Verificar que pytest est√© instalado
pip list | Select-String "pytest"

# 3. Si no est√°, instalarlo
pip install -r requirements.txt

# 4. Verificar instalaci√≥n
pytest --version
```

### Problema 2: API no est√° disponible

**Error:**
```
SKIPPED [1] tests/conftest.py:45: API no responde
```

**Soluci√≥n:**
```powershell
# 1. Verificar que el API est√© corriendo
Test-NetConnection -ComputerName localhost -Port 8000

# 2. Verificar en navegador
start http://localhost:8000/docs

# 3. Si el API est√° en otra URL, actualizar .env
notepad .env
# Cambiar API_BASE_URL seg√∫n corresponda

# 4. Reiniciar el API si es necesario
```

### Problema 3: Timeout en tests

**Error:**
```
requests.exceptions.Timeout: HTTPConnectionPool(host='localhost', port=8000): Read timed out.
```

**Soluci√≥n:**
```powershell
# 1. Aumentar timeout en .env
notepad .env
# Cambiar API_TIMEOUT=5 a API_TIMEOUT=10

# 2. O ejecutar con marker excluyendo timeout
pytest -m "not timeout"

# 3. Verificar que el API responda r√°pido
# curl o Postman para probar manualmente
```

### Problema 4: ModuleNotFoundError

**Error:**
```
ModuleNotFoundError: No module named 'pytest'
ModuleNotFoundError: No module named 'requests'
```

**Soluci√≥n:**
```powershell
# 1. Activar entorno virtual
.\venv\Scripts\activate

# 2. Reinstalar dependencias
pip install -r requirements.txt

# 3. Verificar instalaci√≥n
pip list
```

### Problema 5: Tests fallan por datos incorrectos

**Error:**
```
AssertionError: Status code esperado 200, recibido: 404
```

**Soluci√≥n:**
```powershell
# 1. Verificar que el API tenga los datos de prueba esperados
# Revisar: tests/test_data/bureau_test_data.py

# 2. Ajustar datos de prueba seg√∫n tu API
notepad tests\test_data\bureau_test_data.py

# 3. O configurar API mock
# En .env: ENABLE_MOCK=true
```

### Problema 6: Variables de entorno no cargadas

**Error:**
```
KeyError: 'API_BASE_URL'
```

**Soluci√≥n:**
```powershell
# 1. Verificar que existe .env
if (Test-Path .env) { "Archivo existe" } else { "Archivo NO existe" }

# 2. Si no existe, crearlo desde el ejemplo
cp .env.example .env

# 3. Verificar contenido
cat .env

# 4. Editar si es necesario
notepad .env
```

### Problema 7: Permisos de ejecuci√≥n en Windows

**Error:**
```
cannot be loaded because running scripts is disabled on this system
```

**Soluci√≥n:**
```powershell
# Ejecutar PowerShell como Administrador y ejecutar:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Luego reintenta activar el entorno virtual
.\venv\Scripts\activate
```

### Problema 8: Puerto 8000 ocupado

**Error:**
```
Connection refused [Errno 111]
```

**Soluci√≥n:**
```powershell
# 1. Verificar qu√© proceso usa el puerto 8000
netstat -ano | findstr :8000

# 2. Detener el proceso si es necesario
# Anota el PID y ejecuta:
Stop-Process -Id <PID>

# 3. O cambiar la URL en .env a otro puerto
notepad .env
# API_BASE_URL=http://localhost:8001
```

---

## üí° Ejemplos Pr√°cticos

### Ejemplo 1: Primera Ejecuci√≥n Completa

```powershell
# Paso 1: Ir al directorio
cd C:\Users\1577089\Desktop\CapacitacionIA-Banistmo\CapacitacionIA-Banistmo

# Paso 2: Activar entorno virtual
.\venv\Scripts\activate

# Paso 3: Verificar API
start http://localhost:8000/docs

# Paso 4: Ejecutar solo tests cr√≠ticos primero
pytest -m critical -v

# Paso 5: Si todo pasa, ejecutar suite completa
pytest -v

# Paso 6: Generar reporte HTML
pytest --html=report.html --self-contained-html
start report.html
```

### Ejemplo 2: Debugging de un Test Espec√≠fico

```powershell
# Ejecutar un test espec√≠fico con m√°ximo detalle
pytest tests/test_bureau_happy_path.py::TestBureauHappyPath::test_tc_bc_001_cliente_buen_historial -vv -s

# Explicaci√≥n de flags:
# -vv: Muy verbose (m√°ximo detalle)
# -s: Muestra prints y outputs
```

### Ejemplo 3: Ejecutar Solo Tests R√°pidos

```powershell
# Ejecutar solo tests de validaci√≥n (sin integraci√≥n real)
pytest -m validation -v

# Son m√°s r√°pidos porque no dependen tanto del API
```

### Ejemplo 4: Pipeline de CI/CD

```powershell
# Simular ejecuci√≥n de CI/CD

# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Ejecutar tests cr√≠ticos con reporte JUnit
pytest -m critical --junitxml=report.xml -v

# 3. Si cr√≠ticos pasan, ejecutar suite completa
if ($LASTEXITCODE -eq 0) {
    pytest --junitxml=full_report.xml -v
}

# 4. Generar reporte HTML
pytest --html=report.html --self-contained-html
```

### Ejemplo 5: Desarrollo Diario

```powershell
# Workflow t√≠pico durante desarrollo:

# 1. Activar entorno
.\venv\Scripts\activate

# 2. Hacer cambios en el c√≥digo...

# 3. Ejecutar tests afectados
pytest tests/test_bureau_validations.py -v

# 4. Si pasa, ejecutar suite de regresi√≥n
pytest -m regression -x

# 5. Antes de commit, ejecutar cr√≠ticos + alta
pytest -m "critical or high" -v
```

### Ejemplo 6: An√°lisis de Cobertura

```powershell
# Instalar plugin de cobertura
pip install pytest-cov

# Ejecutar con an√°lisis de cobertura
pytest --cov=tests --cov-report=html --cov-report=term

# Ver reporte en terminal y HTML
start htmlcov/index.html
```

### Ejemplo 7: Ejecutar Tests en Paralelo (M√°s R√°pido)

```powershell
# Instalar plugin de paralelizaci√≥n
pip install pytest-xdist

# Ejecutar tests en paralelo (4 workers)
pytest -n 4

# O usar todos los cores disponibles
pytest -n auto
```

---

## üìö Referencias Adicionales

### Archivos de Documentaci√≥n

- **QUICKSTART.md** - Gu√≠a r√°pida de 3 minutos
- **MANUAL_PRUEBAS.md** - Manual detallado con todos los casos
- **README.md** - Documentaci√≥n principal del proyecto
- **VERIFICACION.md** - Checklist de verificaci√≥n
- **RESUMEN.py** - Resumen ejecutable del proyecto

### Estructura de Tests

```
tests/
‚îú‚îÄ‚îÄ conftest.py                      # Fixtures y configuraci√≥n global
‚îú‚îÄ‚îÄ test_bureau_happy_path.py        # 4 tests - Path feliz (TC-BC-001 a 004)
‚îú‚îÄ‚îÄ test_bureau_validations.py      # 6 tests - Validaciones (TC-BC-005 a 007)
‚îú‚îÄ‚îÄ test_bureau_errors.py            # 5 tests - Manejo errores (TC-BC-008, 009, 015)
‚îú‚îÄ‚îÄ test_bureau_edge_cases.py       # 6 tests - Edge cases (TC-BC-010 a 014)
‚îú‚îÄ‚îÄ helpers/
‚îÇ   ‚îî‚îÄ‚îÄ api_client.py                # Cliente HTTP reutilizable
‚îî‚îÄ‚îÄ test_data/
    ‚îî‚îÄ‚îÄ bureau_test_data.py          # Datos centralizados
```

### Markers Disponibles

```python
@pytest.mark.critical     # Tests bloqueantes (P0)
@pytest.mark.high         # Alta prioridad (P1)
@pytest.mark.medium       # Prioridad media (P2)
@pytest.mark.smoke        # Tests de humo
@pytest.mark.regression   # Suite de regresi√≥n
@pytest.mark.integration  # Tests de integraci√≥n
@pytest.mark.validation   # Validaciones de entrada
@pytest.mark.edge_case    # Casos extremos
@pytest.mark.timeout      # Tests con timeout
```

### Comandos R√°pidos de Referencia

```powershell
# Activar entorno
.\venv\Scripts\activate

# Listar tests
pytest --collect-only

# Tests cr√≠ticos
pytest -m critical

# Con reporte
pytest --html=report.html --self-contained-html

# Verbose
pytest -v

# Detener en error
pytest -x

# Solo √∫ltimo fallido
pytest --lf
```

---

## üéì Mejores Pr√°cticas

### Antes de Ejecutar Tests

1. ‚úÖ Activar entorno virtual
2. ‚úÖ Verificar que el API est√© corriendo
3. ‚úÖ Revisar archivo .env
4. ‚úÖ Ejecutar tests cr√≠ticos primero

### Durante el Desarrollo

1. ‚úÖ Ejecutar tests relacionados despu√©s de cada cambio
2. ‚úÖ Usar `-x` para detener en primer error
3. ‚úÖ Usar `-v` para ver detalles
4. ‚úÖ Revisar logs con `-s` si hay fallos

### Antes de Commit

1. ‚úÖ Ejecutar suite de regresi√≥n
2. ‚úÖ Verificar que no hay tests skipped inesperadamente
3. ‚úÖ Generar reporte si es necesario
4. ‚úÖ Revisar cobertura de c√≥digo

### En CI/CD

1. ‚úÖ Ejecutar tests cr√≠ticos primero
2. ‚úÖ Generar reportes JUnit XML
3. ‚úÖ Configurar timeout apropiado
4. ‚úÖ Archivar reportes HTML

---

## üìû Soporte

Para m√°s ayuda:
- üìñ Consultar `MANUAL_PRUEBAS.md`
- üöÄ Ver `QUICKSTART.md`
- üåê Documentaci√≥n API: http://localhost:8000/docs
- üìã Casos de prueba SVE: `test_cases_sve.csv`, `test_cases_sve.txt`, `test_cases_sve.json`

---

## ‚úÖ Checklist Final

Antes de comenzar, verifica:

- [ ] Python 3.8+ instalado
- [ ] pip actualizado
- [ ] Entorno virtual creado y activado
- [ ] Dependencias instaladas (`pip install -r requirements.txt`)
- [ ] Archivo `.env` configurado
- [ ] API corriendo en localhost:8000
- [ ] pytest funcionando (`pytest --version`)
- [ ] Tests listados correctamente (`pytest --collect-only`)

**¬°Listo para probar!** üéâ

```powershell
pytest -m critical -v
```

---

**√öltima actualizaci√≥n:** 2025-12-09  
**Versi√≥n:** 1.0  
**Proyecto:** Capacitaci√≥n IA - Banistmo
