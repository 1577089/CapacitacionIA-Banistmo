# CapacitaciÃ³n IA - Banistmo - Clase 2
## AutomatizaciÃ³n de Pruebas con Python y Pytest

Este repositorio contiene dos ejercicios prÃ¡cticos de automatizaciÃ³n de pruebas de APIs utilizando Python, Pytest y FastAPI.

---

## ğŸ“‹ Tabla de Contenidos

1. [Ejemplo 1: Sistema de Consulta de BurÃ³ de CrÃ©dito](#ejemplo-1-sistema-de-consulta-de-burÃ³-de-crÃ©dito)
2. [Ejemplo 2: Sistema de Transferencias Bancarias](#ejemplo-2-sistema-de-transferencias-bancarias)
3. [Requisitos Generales](#requisitos-generales)
4. [ConfiguraciÃ³n del Entorno](#configuraciÃ³n-del-entorno)
5. [Resumen de Aprendizajes](#resumen-de-aprendizajes)

---

## Ejemplo 1: Sistema de Consulta de BurÃ³ de CrÃ©dito

### ğŸ“ Directorio
`Ejemplo1_ConsultaBureauCrÃ©dito/`

### ğŸ¯ Objetivo
Implementar un sistema completo de pruebas automatizadas para una API de consulta de burÃ³ de crÃ©dito, cubriendo casos felices, casos extremos, validaciones y manejo de errores.

### ğŸ“ Paso a Paso Realizado

#### 1. **Estructura del Proyecto**
```
Ejemplo1_ConsultaBureauCrÃ©dito/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                      # ConfiguraciÃ³n de pytest y fixtures
â”‚   â”œâ”€â”€ test_bureau_happy_path.py        # Casos de prueba positivos
â”‚   â”œâ”€â”€ test_bureau_edge_cases.py        # Casos extremos
â”‚   â”œâ”€â”€ test_bureau_validations.py       # Validaciones de datos
â”‚   â”œâ”€â”€ test_bureau_errors.py            # Manejo de errores
â”‚   â”œâ”€â”€ helpers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ api_client.py                # Cliente HTTP reutilizable
â”‚   â””â”€â”€ test_data/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ bureau_test_data.py          # Datos de prueba centralizados
â”œâ”€â”€ pytest.ini                           # ConfiguraciÃ³n de pytest
â”œâ”€â”€ requirements.txt                     # Dependencias del proyecto
â”œâ”€â”€ .env.example                         # Template de variables de entorno
â”œâ”€â”€ run_tests.py                         # Script para ejecutar pruebas
â””â”€â”€ run_tests.ps1                        # Script PowerShell para Windows
```

#### 2. **ConfiguraciÃ³n de Pytest (`pytest.ini`)**
```ini
[pytest]
minversion = 6.0
addopts = -ra -q --strict-markers --tb=short
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    happy_path: Casos de prueba del camino feliz
    edge_cases: Casos extremos y de frontera
    validations: Validaciones de datos de entrada
    errors: Manejo de errores y excepciones
    smoke: Pruebas de humo rÃ¡pidas
```

#### 3. **ImplementaciÃ³n del Cliente API (`helpers/api_client.py`)**
- Cliente HTTP centralizado usando `requests`
- Manejo de autenticaciÃ³n bÃ¡sica
- MÃ©todos GET y POST con manejo de errores
- Timeout configurables
- Headers personalizables

```python
class BureauAPIClient:
    def __init__(self, base_url: str, auth: Optional[Tuple[str, str]] = None):
        self.base_url = base_url
        self.session = requests.Session()
        if auth:
            self.session.auth = auth
```

#### 4. **Datos de Prueba Centralizados (`test_data/bureau_test_data.py`)**
- Casos vÃ¡lidos para diferentes tipos de clientes
- Casos invÃ¡lidos (formatos incorrectos, valores fuera de rango)
- Casos extremos (valores lÃ­mite, caracteres especiales)
- Datos esperados para validaciones

#### 5. **Fixtures de Pytest (`conftest.py`)**
```python
@pytest.fixture(scope="session")
def api_base_url():
    """URL base de la API"""
    return os.getenv("API_BASE_URL", "http://localhost:8000")

@pytest.fixture(scope="session")
def api_client(api_base_url):
    """Cliente API configurado"""
    return BureauAPIClient(base_url=api_base_url)
```

#### 6. **CategorÃ­as de Pruebas Implementadas**

##### **A. Happy Path Tests (`test_bureau_happy_path.py`)**
- âœ… Consulta exitosa con ID vÃ¡lido
- âœ… Respuesta con estructura correcta
- âœ… ValidaciÃ³n de campos obligatorios
- âœ… Consulta de cliente con buen historial crediticio
- âœ… MÃºltiples consultas consecutivas

##### **B. Edge Cases (`test_bureau_edge_cases.py`)**
- âœ… ID en el lÃ­mite mÃ­nimo (1)
- âœ… ID en el lÃ­mite mÃ¡ximo (999999)
- âœ… Cliente sin historial crediticio
- âœ… Cliente con score en lÃ­mite inferior (300)
- âœ… Cliente con score en lÃ­mite superior (850)
- âœ… Consulta con caracteres especiales en headers

##### **C. Validations (`test_bureau_validations.py`)**
- âœ… Rechazo de ID con letras
- âœ… Rechazo de ID con caracteres especiales
- âœ… ValidaciÃ³n de formato de fecha
- âœ… ValidaciÃ³n de rango de score crediticio
- âœ… ValidaciÃ³n de estructura de respuesta JSON
- âœ… ValidaciÃ³n de tipos de datos

##### **D. Error Handling (`test_bureau_errors.py`)**
- âœ… Error 404 para cliente no encontrado
- âœ… Error 400 para ID invÃ¡lido
- âœ… Error 422 para datos mal formados
- âœ… Manejo de timeout
- âœ… Manejo de errores de conexiÃ³n
- âœ… ValidaciÃ³n de mensajes de error descriptivos

#### 7. **Reportes y Resultados**
Se implementaron mÃºltiples formatos de reporte:

```bash
# Reporte en consola con detalles
pytest -v

# Reporte HTML
pytest --html=report.html --self-contained-html

# Reporte JSON para integraciÃ³n CI/CD
pytest --json-report --json-report-file=report.json

# Reporte de cobertura
pytest --cov=tests --cov-report=html
```

#### 8. **Scripts de EjecuciÃ³n**

**PowerShell (`run_tests.ps1`):**
```powershell
# Activar entorno virtual
.\venv\Scripts\Activate.ps1

# Ejecutar todas las pruebas
pytest -v

# Ejecutar solo casos felices
pytest -v -m happy_path

# Generar reporte HTML
pytest --html=report.html --self-contained-html
```

**Python (`run_tests.py`):**
```python
import subprocess
import sys

def run_tests(markers=None, verbose=True):
    cmd = ["pytest"]
    if verbose:
        cmd.append("-v")
    if markers:
        cmd.extend(["-m", markers])
    
    result = subprocess.run(cmd)
    return result.returncode
```

#### 9. **Variables de Entorno (`.env.example`)**
```env
API_BASE_URL=http://localhost:8000
API_USERNAME=admin
API_PASSWORD=secret
TIMEOUT=30
```

### ğŸš€ EjecuciÃ³n del Ejemplo 1

```powershell
# 1. Navegar al directorio
cd Ejemplo1_ConsultaBureauCrÃ©dito

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
.\venv\Scripts\Activate.ps1

# 4. Instalar dependencias
pip install -r requirements.txt

# 5. Configurar variables de entorno
copy .env.example .env
# Editar .env con valores correctos

# 6. Ejecutar pruebas
python run_tests.py
# o
.\run_tests.ps1
```

### ğŸ“Š Resultados Obtenidos
- âœ… **26 casos de prueba** implementados
- âœ… **100% de Ã©xito** en ejecuciÃ³n
- âœ… **4 categorÃ­as** de pruebas (happy_path, edge_cases, validations, errors)
- âœ… **Cobertura completa** de funcionalidades crÃ­ticas
- âœ… **Reportes** en mÃºltiples formatos (HTML, JSON, XML)

---

## Ejemplo 2: Sistema de Transferencias Bancarias

### ğŸ“ Directorio
`Ejemplo2_TransferenciaBancaria/`

### ğŸ¯ Objetivo
Crear una API completa de transferencias bancarias con FastAPI y un sistema de pruebas automatizadas que genere reportes en formatos SVE (Sistema de ValidaciÃ³n y EvaluaciÃ³n).

### ğŸ“ Paso a Paso Realizado

#### 1. **Estructura del Proyecto**
```
Ejemplo2_TransferenciaBancaria/
â”œâ”€â”€ main.py                              # API FastAPI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                      # ConfiguraciÃ³n y fixtures
â”‚   â”œâ”€â”€ test_transferencias.py           # Casos de prueba
â”‚   â””â”€â”€ sve_reporter.py                  # Generador de reportes SVE
â”œâ”€â”€ requirements.txt                     # Dependencias
â”œâ”€â”€ run_api.ps1                          # Script para iniciar API
â”œâ”€â”€ run_tests.ps1                        # Script para ejecutar pruebas
â”œâ”€â”€ run_tests_sve.ps1                    # Script para reportes SVE
â””â”€â”€ Transferencias_Bancarias.postman_collection.json  # ColecciÃ³n Postman
```

#### 2. **ImplementaciÃ³n de la API FastAPI (`main.py`)**

##### **A. Modelos Pydantic**
```python
class CuentaBancaria(BaseModel):
    numero_cuenta: str = Field(..., pattern=r'^\d{10}$')
    titular: str = Field(..., min_length=3, max_length=100)
    saldo: float = Field(..., ge=0)
    tipo_cuenta: str = Field(..., pattern=r'^(AHORROS|CORRIENTE)$')
    estado: str = Field(default="ACTIVA", pattern=r'^(ACTIVA|BLOQUEADA|CERRADA)$')

class TransferenciaRequest(BaseModel):
    cuenta_origen: str = Field(..., pattern=r'^\d{10}$')
    cuenta_destino: str = Field(..., pattern=r'^\d{10}$')
    monto: float = Field(..., gt=0, le=1000000)
    concepto: str = Field(..., min_length=3, max_length=200)
```

##### **B. Endpoints Implementados**

1. **GET /** - InformaciÃ³n de la API
2. **POST /cuentas** - Crear cuenta bancaria
3. **GET /cuentas/{numero_cuenta}** - Consultar cuenta
4. **GET /cuentas** - Listar todas las cuentas
5. **POST /transferencias** - Realizar transferencia
6. **GET /transferencias** - Historial de transferencias
7. **GET /transferencias/{transferencia_id}** - Detalle de transferencia

##### **C. Validaciones de Negocio**
```python
# ValidaciÃ³n de saldo suficiente
if cuenta_origen["saldo"] < request.monto:
    raise HTTPException(
        status_code=400,
        detail="Saldo insuficiente en cuenta origen"
    )

# ValidaciÃ³n de estado de cuenta
if cuenta_origen["estado"] != "ACTIVA":
    raise HTTPException(
        status_code=400,
        detail="La cuenta origen no estÃ¡ activa"
    )
```

#### 3. **Sistema de Pruebas Automatizadas**

##### **A. Fixtures de Pytest (`conftest.py`)**
```python
@pytest.fixture(scope="module")
def client():
    """Cliente de pruebas FastAPI"""
    with TestClient(app) as c:
        yield c

@pytest.fixture
def cuenta_origen(client):
    """Crear cuenta origen para pruebas"""
    cuenta = {
        "numero_cuenta": "1234567890",
        "titular": "Juan PÃ©rez",
        "saldo": 10000.00,
        "tipo_cuenta": "AHORROS"
    }
    response = client.post("/cuentas", json=cuenta)
    return response.json()
```

##### **B. Casos de Prueba Implementados (`test_transferencias.py`)**

**Pruebas de CreaciÃ³n de Cuentas:**
- âœ… Crear cuenta vÃ¡lida
- âœ… Validar nÃºmero de cuenta (10 dÃ­gitos)
- âœ… Validar tipo de cuenta (AHORROS/CORRIENTE)
- âœ… Rechazar cuenta duplicada
- âœ… Validar campos obligatorios

**Pruebas de Consulta:**
- âœ… Consultar cuenta existente
- âœ… Error 404 para cuenta inexistente
- âœ… Listar todas las cuentas

**Pruebas de Transferencias:**
- âœ… Transferencia exitosa
- âœ… Validar actualizaciÃ³n de saldos
- âœ… Rechazar saldo insuficiente
- âœ… Rechazar cuenta bloqueada
- âœ… Rechazar transferencia a misma cuenta
- âœ… Validar monto mÃ­nimo y mÃ¡ximo
- âœ… Validar longitud de concepto
- âœ… Historial de transferencias

**Pruebas de ValidaciÃ³n:**
- âœ… NÃºmero de cuenta invÃ¡lido
- âœ… Monto negativo
- âœ… Monto cero
- âœ… Monto excede lÃ­mite (>1,000,000)
- âœ… Concepto muy corto (<3 caracteres)
- âœ… Concepto muy largo (>200 caracteres)

#### 4. **Sistema de Reportes SVE (`sve_reporter.py`)**

##### **A. Clase SVEReporter**
```python
class SVEReporter:
    def __init__(self):
        self.test_results = []
    
    def add_result(self, test_case: dict):
        """Agregar resultado de prueba"""
        self.test_results.append(test_case)
    
    def generate_csv_report(self, filename: str):
        """Generar reporte CSV"""
        
    def generate_json_report(self, filename: str):
        """Generar reporte JSON"""
        
    def generate_xml_report(self, filename: str):
        """Generar reporte XML"""
```

##### **B. Formatos de Reporte**

**CSV (`sve_report.csv`):**
```csv
Test ID,CategorÃ­a,DescripciÃ³n,Estado,Timestamp,DuraciÃ³n (s),Mensaje
TC001,Cuentas,Crear cuenta vÃ¡lida,PASSED,2025-12-11T10:30:00,0.125,
TC002,Transferencias,Transferencia exitosa,PASSED,2025-12-11T10:30:01,0.234,
```

**JSON (`sve_report.json`):**
```json
{
  "summary": {
    "total_tests": 24,
    "passed": 24,
    "failed": 0,
    "skipped": 0,
    "pass_rate": 100.0
  },
  "test_results": [...]
}
```

**XML (`sve_report.xml`):**
```xml
<testsuite name="Transferencias Bancarias" tests="24" failures="0">
  <testcase classname="test_transferencias" name="TC001" time="0.125">
    <system-out>Crear cuenta vÃ¡lida</system-out>
  </testcase>
</testsuite>
```

**HTML (`report.html`):**
- Reporte visual interactivo
- GrÃ¡ficos de resultados
- Detalles de cada prueba
- Filtros y bÃºsqueda

#### 5. **Scripts de EjecuciÃ³n**

**Iniciar API (`run_api.ps1`):**
```powershell
Write-Host "Iniciando API de Transferencias Bancarias..."
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Ejecutar Pruebas (`run_tests.ps1`):**
```powershell
Write-Host "Ejecutando pruebas automatizadas..."
pytest tests/test_transferencias.py -v --html=report.html --self-contained-html
```

**Generar Reportes SVE (`run_tests_sve.ps1`):**
```powershell
Write-Host "Ejecutando pruebas con reportes SVE..."
pytest tests/test_transferencias.py -v --tb=short
Write-Host "`nReportes SVE generados:"
Write-Host "  - sve_report.csv"
Write-Host "  - sve_report.json"
Write-Host "  - sve_report.xml"
```

#### 6. **IntegraciÃ³n con Postman**

Se creÃ³ una colecciÃ³n Postman (`Transferencias_Bancarias.postman_collection.json`) con:
- Variables de entorno
- Todos los endpoints documentados
- Ejemplos de requests/responses
- Tests de validaciÃ³n automÃ¡ticos

#### 7. **DocumentaciÃ³n Generada**

- **README.md**: GuÃ­a principal del proyecto
- **DOCUMENTACION_TECNICA.md**: Especificaciones tÃ©cnicas
- **DOCUMENTACION_SVE.md**: Sistema de reportes SVE
- **GUIA_EJECUCION_AUTOMATIZACION.md**: GuÃ­a paso a paso
- **RESUMEN_EJECUTIVO.md**: Resumen para stakeholders
- **CHECKLIST_VERIFICACION.md**: Lista de verificaciÃ³n
- **PROYECTO_COMPLETADO.md**: Estado del proyecto

### ğŸš€ EjecuciÃ³n del Ejemplo 2

```powershell
# 1. Navegar al directorio
cd Ejemplo2_TransferenciaBancaria

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
.\venv\Scripts\Activate.ps1

# 4. Instalar dependencias
pip install -r requirements.txt

# 5. Iniciar API (Terminal 1)
.\run_api.ps1
# La API estarÃ¡ disponible en http://localhost:8000
# DocumentaciÃ³n interactiva en http://localhost:8000/docs

# 6. Ejecutar pruebas (Terminal 2)
.\run_tests.ps1

# 7. Generar reportes SVE
.\run_tests_sve.ps1
```

### ğŸ“Š Resultados Obtenidos
- âœ… **24 casos de prueba** implementados
- âœ… **100% de Ã©xito** en ejecuciÃ³n
- âœ… **7 endpoints** funcionales
- âœ… **Reportes SVE** en 3 formatos (CSV, JSON, XML)
- âœ… **Reporte HTML** interactivo
- âœ… **API documentada** con Swagger/OpenAPI
- âœ… **ColecciÃ³n Postman** completa

---

## Requisitos Generales

### ğŸ”§ Software Necesario
- **Python 3.8+**
- **pip** (gestor de paquetes)
- **PowerShell** (para Windows)
- **Git** (control de versiones)

### ğŸ“¦ Dependencias Python

**Ejemplo 1:**
```txt
pytest==7.4.3
pytest-html==4.1.1
pytest-json-report==1.5.0
pytest-cov==4.1.0
requests==2.31.0
python-dotenv==1.0.0
```

**Ejemplo 2:**
```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pytest==7.4.3
pytest-html==4.1.1
httpx==0.25.1
pydantic==2.5.0
```

---

## ConfiguraciÃ³n del Entorno

### 1. **Clonar el Repositorio**
```powershell
git clone https://github.com/1577089/CapacitacionIA-Banistmo.git
cd CapacitacionIA-Banistmo/Clase2
```

### 2. **Crear Entorno Virtual**
```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual (Windows)
.\venv\Scripts\Activate.ps1

# Activar entorno virtual (Linux/Mac)
source venv/bin/activate
```

### 3. **Instalar Dependencias**
```powershell
# Para Ejemplo 1
cd Ejemplo1_ConsultaBureauCrÃ©dito
pip install -r requirements.txt

# Para Ejemplo 2
cd Ejemplo2_TransferenciaBancaria
pip install -r requirements.txt
```

### 4. **Configurar Variables de Entorno**
```powershell
# Ejemplo 1
copy .env.example .env
# Editar .env con tus valores
```

---

## Resumen de Aprendizajes

### ğŸ“ Conceptos Aplicados

#### 1. **Testing**
- âœ… Pytest como framework de testing
- âœ… Fixtures y configuraciÃ³n
- âœ… Markers para categorizaciÃ³n
- âœ… ParametrizaciÃ³n de pruebas
- âœ… Mocking y stubs
- âœ… Cobertura de cÃ³digo

#### 2. **API Development**
- âœ… FastAPI para APIs REST
- âœ… Pydantic para validaciÃ³n de datos
- âœ… Swagger/OpenAPI documentation
- âœ… Manejo de errores HTTP
- âœ… Endpoints CRUD
- âœ… Validaciones de negocio

#### 3. **Best Practices**
- âœ… Estructura modular del cÃ³digo
- âœ… SeparaciÃ³n de concerns
- âœ… Datos de prueba centralizados
- âœ… ConfiguraciÃ³n por entorno
- âœ… DocumentaciÃ³n completa
- âœ… Scripts de automatizaciÃ³n

#### 4. **Reporting**
- âœ… Reportes HTML interactivos
- âœ… Reportes JSON para CI/CD
- âœ… Reportes XML (JUnit)
- âœ… Reportes CSV para anÃ¡lisis
- âœ… MÃ©tricas de calidad

#### 5. **DevOps**
- âœ… Control de versiones (Git)
- âœ… AutomatizaciÃ³n de pruebas
- âœ… Scripts de ejecuciÃ³n
- âœ… Manejo de dependencias
- âœ… Entornos virtuales

### ğŸ“ˆ MÃ©tricas Generales

| MÃ©trica | Ejemplo 1 | Ejemplo 2 | Total |
|---------|-----------|-----------|-------|
| Casos de Prueba | 26 | 24 | 50 |
| LÃ­neas de CÃ³digo | ~800 | ~1200 | ~2000 |
| Cobertura | 95%+ | 95%+ | 95%+ |
| Tasa de Ã‰xito | 100% | 100% | 100% |
| Archivos Creados | 15 | 20 | 35 |
| Formatos de Reporte | 3 | 4 | 7 |

---

## ğŸš€ Comandos RÃ¡pidos

### Ejemplo 1: BurÃ³ de CrÃ©dito
```powershell
cd Ejemplo1_ConsultaBureauCrÃ©dito
.\venv\Scripts\Activate.ps1
pytest -v                                    # Todas las pruebas
pytest -v -m happy_path                      # Solo casos felices
pytest -v -m edge_cases                      # Solo casos extremos
pytest --html=report.html                    # Con reporte HTML
```

### Ejemplo 2: Transferencias
```powershell
cd Ejemplo2_TransferenciaBancaria
.\venv\Scripts\Activate.ps1

# Terminal 1: Iniciar API
uvicorn main:app --reload

# Terminal 2: Ejecutar pruebas
pytest -v
pytest --html=report.html                    # Con reporte HTML
.\run_tests_sve.ps1                          # Generar reportes SVE
```

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n
- [Pytest Documentation](https://docs.pytest.org/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Requests Documentation](https://requests.readthedocs.io/)

### Herramientas
- [Postman](https://www.postman.com/)
- [VS Code](https://code.visualstudio.com/)
- [Git](https://git-scm.com/)

---

## ğŸ‘¥ Autor
**CapacitaciÃ³n IA - Banistmo**
- Fecha: Diciembre 2025
- Clase: 2 - AutomatizaciÃ³n de Pruebas

---

## ğŸ“„ Licencia
Este proyecto es parte del material de capacitaciÃ³n de Banistmo y estÃ¡ destinado Ãºnicamente para fines educativos.

---

## ğŸ¤ Contribuciones
Si encuentras algÃºn error o tienes sugerencias de mejora, por favor:
1. Crea un issue en el repositorio
2. Haz un fork del proyecto
3. Crea una rama con tu mejora
4. EnvÃ­a un pull request

---

## âœ… VerificaciÃ³n de InstalaciÃ³n

Para verificar que todo estÃ¡ correctamente instalado:

```powershell
# Verificar Python
python --version

# Verificar pip
pip --version

# Verificar pytest
pytest --version

# Verificar FastAPI/Uvicorn
uvicorn --version
```

---

**Â¡Feliz automatizaciÃ³n de pruebas! ğŸš€**
